{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 29131 中有 9131 个触发bug\n",
      "67 83\n",
      "Comp_Model(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (encoder): MPN(\n",
      "    (encoder): MPNEncoder(\n",
      "      (dropout_layer): Dropout(p=0.3, inplace=False)\n",
      "      (act_func): ReLU()\n",
      "      (node_attention): NodeAttention(\n",
      "        (transform_edge): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (tranform_node): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (fc): Linear(in_features=800, out_features=1, bias=True)\n",
      "      )\n",
      "      (edge_attention): EdgeAttention(\n",
      "        (tranform_node): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (tranform_edge): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (attention_fc): Linear(in_features=800, out_features=2, bias=True)\n",
      "      )\n",
      "      (W_i): Linear(in_features=83, out_features=400, bias=True)\n",
      "      (W_i_nodes): Linear(in_features=67, out_features=400, bias=True)\n",
      "      (W_e): Linear(in_features=800, out_features=400, bias=True)\n",
      "      (W_h): Linear(in_features=400, out_features=400, bias=True)\n",
      "      (W_o): Linear(in_features=467, out_features=400, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (ffn): Sequential(\n",
      "    (0): Dropout(p=0.3, inplace=False)\n",
      "    (1): Linear(in_features=468, out_features=300, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=300, out_features=300, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.3, inplace=False)\n",
      "    (7): Linear(in_features=300, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from typing import Union\n",
    "from typing import Iterator\n",
    "from typing import Optional\n",
    "import re\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import ast\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from random import Random\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "\n",
    "import onnx\n",
    "import tvm\n",
    "from tvm.relay.frontend import onnx as ox\n",
    "from tvm import relay\n",
    "from tvm.autotvm.graph_tuner.utils import expr2graph\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim import Adam, Optimizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "op_names = [\n",
    "\"torch.Linear\", \"core.Reshape\", \"core.ReplicatePad \", \"core.ReLU\", \n",
    "\"core.ExpandLast1\", \"core.Sub\", \"core.NCHWConv2d\", \"core.Tril\", \"core.Mul\", \n",
    "\"core.Clip\", \"core.Atan\", \"core.Squeeze\", \"core.ReduceMax\", \"core.Or\", \n",
    "\"core.NearestInterp\", \"core.ExpandLast4\", \"core.Conv1d\", \"core.Min\", \n",
    "\"None\", \"core.Max\", \"Concat \", \"core.Transpose\", \"core.Round\", \"core.ArgMax\", \n",
    "\"core.Where\", \"core.GELU\", \"core.AvgPool2d\", \"core.Ceil\", \"core.BatchNorm2d\", \n",
    "\"Constant\", \"core.LeakyReLU\", \"core.Sigmoid\", \"core.ReduceMean\", \"core.Add\", \n",
    "\"core.Neg\", \"core.Triu\", \"core.TrilinearInterp\", \"core.Floor\", \"core.ArgMin\", \n",
    "\"core.Div\", \"core.Xor\", \"core.Slice \", \"core.BilinearInterp\", \"core.LinearInterp\", \n",
    "\"core.Abs\", \"core.Equal\", \"core.ConstPad \", \"torch.Flatten\", \"core.And\", \"Input\", \n",
    "\"Cast \", \"torch.TorchReduceSum\", \"core.Cos\", \"core.ExpandLast2\", \"core.Softmax\", \n",
    "\"core.Sin\", \"core.MaxPool2d\", \"core.BicubicInterp\", \"core.Less\", \"core.PReLU\", \n",
    "\"core.ExpandLast3\", \"core.ReduceMin\", \"core.ReflectPad \", \"core.Tan\", \"core.Greater\"\n",
    "]\n",
    "\n",
    "data_type_names = [\n",
    "    \"i64\", \"i32\", \"b\", \"i8\", \"f64\", \"i16\", \"Unknow\", \"f32\", \"f16\", \"u8\"\n",
    "]\n",
    "\n",
    "vocab = {op:  idx for idx, op in enumerate(op_names)}\n",
    "op_vocab = {op: idx for idx, op in enumerate(op_names)}\n",
    "\n",
    "# Load the dataset from the JSON file\n",
    "json_filename = 'train.json'\n",
    "with open(json_filename, 'r') as jsonfile:\n",
    "    loaded_dataset_dicts = json.load(jsonfile)\n",
    "\n",
    "# Extract the lists from the loaded dataset\n",
    "node_info_set = [item['node_info'] for item in loaded_dataset_dicts]\n",
    "edge_info_set = [item['edge_info'] for item in loaded_dataset_dicts]\n",
    "graph_info_set = [item['graph_info'] for item in loaded_dataset_dicts]\n",
    "result_set = [item['result'] for item in loaded_dataset_dicts]\n",
    "count_result = 0\n",
    "count_true_result = 0\n",
    "for result in result_set:\n",
    "    if result == 1:\n",
    "        count_true_result += 1\n",
    "    count_result += 1\n",
    "print(\"在\",count_result,\"中有\",count_true_result,\"个触发bug\")\n",
    "\n",
    "def onek_encoding_unk(value, choices: List):\n",
    "    encoding = [0] * (len(choices) + 1)\n",
    "    index = choices.index(value) if value in choices else -1\n",
    "    encoding[index] = 1\n",
    "\n",
    "    return encoding\n",
    "\n",
    "def node_features(node_info:list):\n",
    "    features = onek_encoding_unk(node_info[1], op_names) \n",
    "    features.append(node_info[2])\n",
    "    return features\n",
    "\n",
    "def edge_features(edge_info:list):\n",
    "    features = []\n",
    "    for i in range(5):\n",
    "        features.append(edge_info[2][i])\n",
    "    tmp_list = onek_encoding_unk(edge_info[3], data_type_names)\n",
    "    for i in range(len(tmp_list)):\n",
    "        features.append(tmp_list[i])\n",
    "    return features\n",
    "\n",
    "# 初始化模型的参数\n",
    "def initialize_weights(model:nn.Module)->None:\n",
    "    for param in model.parameters():\n",
    "        if param.dim() == 1:\n",
    "            nn.init.constant_(param, 0)\n",
    "        else:\n",
    "            nn.init.xavier_normal_(param)\n",
    "\n",
    "def index_select_ND(source: torch.Tensor, index: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Selects the message features from source corresponding to the node or edge indices in index.\n",
    "    \"\"\"\n",
    "    index_size = index.size()  # (num_nodes/num_edges, max_num_edges)\n",
    "    suffix_dim = source.size()[1:]  # (hidden_size,) 也就是source中除了第一个维度之外的所有维度的大小\n",
    "    final_size = index_size + suffix_dim  # (num_nodes/num_edges, max_num_edges, hidden_size)\n",
    "    target = source.index_select(dim=0, index=index.view(-1))  # (num_nodes/num_edges * max_num_edges, hidden_size)\n",
    "    target = target.view(final_size)  # (num_nodes/num_edges, max_num_edges, hidden_size)\n",
    "    return target\n",
    "\n",
    "class TrainArgs:\n",
    "    no_cuda = False\n",
    "    gpu = 0\n",
    "    num_workers = 16\n",
    "    batch_size = 16\n",
    "    dataset_type = 'classification'\n",
    "    task_names = []\n",
    "    num_tasks = 1\n",
    "    seed = 0\n",
    "    hidden_size = 400\n",
    "    bias = False\n",
    "    depth = 3\n",
    "    dropout = 0.3\n",
    "    undirected = False\n",
    "    aggregation = 'norm'\n",
    "    aggregation_norm = 200\n",
    "    cuda = True\n",
    "    ffn_num_layers = 3\n",
    "    ffn_hidden_size = 300\n",
    "    init_lr = 1e-4\n",
    "    max_lr = 1e-3\n",
    "    final_lr = 1e-4\n",
    "    num_lrs = 1\n",
    "    warmup_epochs = 2.0\n",
    "    epochs = 100\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        \"\"\"The :code:`torch.device` on which to load and process data and models.\"\"\"\n",
    "        if not self.cuda:\n",
    "            return torch.device('cpu')\n",
    "\n",
    "        return torch.device('cuda', self.gpu)\n",
    "\n",
    "    @device.setter\n",
    "    def device(self, device: torch.device) -> None:\n",
    "        self.cuda = device.type == 'cuda'\n",
    "        self.gpu = device.index\n",
    "\n",
    "    @property\n",
    "    def cuda(self) -> bool:\n",
    "        \"\"\"Whether to use CUDA (i.e., GPUs) or not.\"\"\"\n",
    "        return not self.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    @cuda.setter\n",
    "    def cuda(self, cuda: bool) -> None:\n",
    "        self.no_cuda = not cuda\n",
    "        \n",
    "args = TrainArgs()\n",
    "\n",
    "node_info = node_info_set[0]\n",
    "edge_info = edge_info_set[0]\n",
    "result = result_set[0]\n",
    "\n",
    "NODE_FDIM = len(node_features(node_info[0]))\n",
    "EDGE_FDIM = len(edge_features(edge_info[0])) + NODE_FDIM\n",
    "print(NODE_FDIM, EDGE_FDIM)\n",
    "\n",
    "def get_node_fdim():\n",
    "    return NODE_FDIM\n",
    "\n",
    "def get_edge_fdim():\n",
    "    return EDGE_FDIM\n",
    "\n",
    "def graph_info_dim():\n",
    "    # 假设 graph_info 的前两个元素是数字\n",
    "    base_dim = 2\n",
    "    op_vector_dim = len(op_vocab) + 1  # 加1是因为有一个额外的类别表示未知的算子\n",
    "    # category_vector_dim = len(category_vocab) + 1  # 加1是因为有一个额外的类别表示未知的类别\n",
    "    return base_dim + op_vector_dim \n",
    "\n",
    "class CompGraphDatapoint:\n",
    "    def __init__(self,\n",
    "                 node_info: list,\n",
    "                 edge_info: list,\n",
    "                 graph_info: list,\n",
    "                 result: int,\n",
    "                 op_vocab: dict,\n",
    "                 ):\n",
    "        self.node_info = node_info\n",
    "        self.edge_info = edge_info\n",
    "        self.graph_info = self.encode_graph_info(graph_info, op_vocab)\n",
    "        self.result = result\n",
    "\n",
    "    def encode_graph_info(self, graph_info, op_vocab):\n",
    "        # 对算子进行编码\n",
    "        ops = graph_info[2]\n",
    "        op_indices = [op_vocab.get(op, len(op_vocab)) for op in ops]\n",
    "\n",
    "        # 对算子类别进行编码\n",
    "        # categories = graph_info[3]\n",
    "        # category_indices = [category_vocab.get(category, len(category_vocab)) for category in categories]\n",
    "\n",
    "        # 创建One-Hot编码向量\n",
    "        op_vector = [0] * (len(op_vocab) + 1)\n",
    "        for idx in op_indices:\n",
    "            op_vector[idx] = 1\n",
    "\n",
    "        # category_vector = [0] * (len(category_vocab) + 1)\n",
    "        # for idx in category_indices:\n",
    "        #     category_vector[idx] = 1\n",
    "\n",
    "        # 合并编码后的向量\n",
    "        encoded_graph_info = graph_info[:2] + op_vector \n",
    "        return encoded_graph_info\n",
    "\n",
    "class CompGraphDataset(Dataset):\n",
    "    def __init__(self, data:List[CompGraphDatapoint]):\n",
    "        self._data = data\n",
    "        self._scaler = None\n",
    "        self._batch_graph = []\n",
    "        self._random = Random()\n",
    "    \n",
    "    def AllCompGraphs(self):\n",
    "        return [(g.node_info, g.edge_info, g.result) for g in self._data]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self._data[item]\n",
    "    \n",
    "    def results(self):\n",
    "        return [d.result for d in self._data]\n",
    "    \n",
    "    def batch_graph(self):   \n",
    "        for d in self._data:\n",
    "            compgraph = CompGraph(d.node_info, d.edge_info)\n",
    "            self._batch_graph.append(compgraph)\n",
    "        return self._batch_graph\n",
    "\n",
    "class CompGraph:\n",
    "    def __init__(self, node_info:list, edge_info:list):\n",
    "        self.n_nodes = 0 # number of nodes\n",
    "        self.n_edges = 0 # number of edges\n",
    "        self.f_nodes = [] # mapping from node index to node features\n",
    "        self.f_edges = [] # mapping from edge index to concat(in_node, edge) features\n",
    "        self.a2b = [] # mapping from node index to incoming edge indices 这里是为了将输入到这个节点的边的信息汇聚过来\n",
    "        self.b2a = [] # mapping from edge index to the incoming node index\n",
    "\n",
    "        # self.node_id_to_index = {node_info[i][0]: i for i in range(len(node_info))}\n",
    "\n",
    "        # # get node features\n",
    "        # self.f_nodes = [node_features(node) for node in node_info]\n",
    "        # self.n_nodes = len(self.f_nodes)\n",
    "\n",
    "        # # initialize node to edge mapping for each ndoe\n",
    "        # for _ in range(self.n_nodes):\n",
    "        #     self.a2b.append([])\n",
    "\n",
    "        # for edge in edge_info:\n",
    "        #     f_edge = edge_features(edge)\n",
    "        #     # 确保 self.f_nodes[edge[0]] 是一个张量\n",
    "        #     # if isinstance(self.f_nodes[edge[0]], list):\n",
    "        #     #     self.f_nodes[edge[0]] = torch.tensor(self.f_nodes[edge[0]])\n",
    "\n",
    "        #     # # 确保 f_edge 是一个张量\n",
    "        #     # if isinstance(f_edge, list):\n",
    "        #     #     f_edge = torch.tensor(f_edge)\n",
    "        #     # self.f_edges.append(torch.cat([self.f_nodes[edge[0]], f_edge], dim=0)) # 这里将边的特征更新为原始的边特征与源点节点特征的拼接concat(in_node_info, edge_info)\n",
    "        #     self.f_edges.append(self.f_nodes[edge[0]] + f_edge)\n",
    "        #     self.a2b[edge[1]].append(edge[4])\n",
    "        #     self.b2a.append(edge[0])\n",
    "        # self.n_edges = len(self.f_edges)\n",
    "\n",
    "        # Build node features and initialize a2b mapping\n",
    "        self.f_nodes = [node_features(node) for node in node_info]\n",
    "        self.n_nodes = len(self.f_nodes)\n",
    "        for _ in range(self.n_nodes):\n",
    "            self.a2b.append([])\n",
    "\n",
    "        # Create a mapping from old node identifiers to new indices\n",
    "        node_id_to_index = {node_info[i][0]: i for i in range(len(node_info))}\n",
    "\n",
    "        # Update edge_info to ensure source and target node identifiers match their index\n",
    "        for edge in edge_info:\n",
    "            source_node_id = edge[0]\n",
    "            target_node_id = edge[1]\n",
    "\n",
    "            # Update source and target node identifiers to match their indices\n",
    "            source_node_index = node_id_to_index[source_node_id]\n",
    "            target_node_index = node_id_to_index[target_node_id]\n",
    "            edge[0] = source_node_index\n",
    "            edge[1] = target_node_index\n",
    "\n",
    "            # Update f_edges with concatenated features\n",
    "            self.f_edges.append(self.f_nodes[source_node_index] + edge_features(edge))\n",
    "\n",
    "            # Update a2b mapping using target node index\n",
    "            self.a2b[target_node_index].append(edge[4])\n",
    "            self.b2a.append(source_node_index)\n",
    "\n",
    "        self.n_edges = len(self.f_edges)\n",
    "\n",
    "    def get_components(self):\n",
    "        return self.f_nodes, self.f_edges, self.a2b, self.b2a\n",
    "    \n",
    "class BatchCompGraph:\n",
    "    '''\n",
    "    处理一个batch的计算图，加速\n",
    "    '''\n",
    "    def __init__(self, comp_graphs:List[CompGraph]):\n",
    "        self.node_fdim = get_node_fdim()\n",
    "        self.edge_fdim = get_edge_fdim()\n",
    "        self.compgraph_count = len(comp_graphs)\n",
    "        # start n_nodes and n_edges at 1 b/c zero padding\n",
    "        self.n_nodes = 1\n",
    "        self.n_edges = 1\n",
    "        self.a_scope = []   # list of tuples indicating (start_node_index, num_nodes) for each graph\n",
    "        self.b_scope = []   # list of tuples indicating (start_edge_index, num_edges) for each graph\n",
    "\n",
    "        # all start with zero padding so that indexing with zero padding returns zeros\n",
    "        f_nodes = [[0] * self.node_fdim]  # node features\n",
    "        f_edges = [[0] * self.edge_fdim]  # combined node/edge features\n",
    "        a2b = [[]]  # mapping from node index to incoming edge indices\n",
    "        b2a = [0]  # mapping from edge index to the index of the node the edge is coming from\n",
    "\n",
    "        for comp_graph in comp_graphs:\n",
    "            f_nodes.extend(comp_graph.f_nodes)\n",
    "            f_edges.extend(comp_graph.f_edges)\n",
    "\n",
    "            for a in range(comp_graph.n_nodes):\n",
    "                a2b.append([b + self.n_edges for b in comp_graph.a2b[a]])\n",
    "\n",
    "            for b in range(comp_graph.n_edges):\n",
    "                b2a.append(self.n_nodes + comp_graph.b2a[b])\n",
    "\n",
    "            self.a_scope.append((self.n_nodes, comp_graph.n_nodes))\n",
    "            self.b_scope.append((self.n_edges, comp_graph.n_edges))\n",
    "            self.n_nodes += comp_graph.n_nodes\n",
    "            self.n_edges += comp_graph.n_edges\n",
    "\n",
    "        self.max_num_edges = max(1, max(len(in_bonds) for in_bonds in a2b))  # max with 1 to fix a crash in case of\n",
    "        # all single-heavy-node graph\n",
    "\n",
    "        self.f_nodes = torch.FloatTensor(f_nodes)\n",
    "        self.f_edges = torch.FloatTensor(f_edges)\n",
    "        self.a2b = torch.LongTensor([a2b[a] + [0] * (self.max_num_edges - len(a2b[a])) for a in range(self.n_nodes)])\n",
    "        self.b2a = torch.LongTensor(b2a)\n",
    "        self.b2b = None  # try to avoid computing b2b b/c O(n_nodes^3)\n",
    "        self.a2a = None  # only needed if using node messages\n",
    "\n",
    "    def get_components(self):\n",
    "        return self.f_nodes, self.f_edges, self.a2b, self.b2a, self.a_scope, self.b_scope\n",
    "    \n",
    "class NodeAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(NodeAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.transform_edge = nn.Linear(hidden_size, hidden_size)\n",
    "        self.tranform_node = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(2 * hidden_size, 1)\n",
    "\n",
    "    def forward(self, h_self, h_neigh):\n",
    "        # h_self: [num_nodes, 1, hidden_size]\n",
    "        # h_neigh: [num_nodes, num_max_edges, hidden_size]\n",
    "        # 将自身状态复制到每个边的数量\n",
    "        h_self = self.tranform_node(h_self)\n",
    "        h_neigh = self.transform_edge(h_neigh)\n",
    "        h_self_expanded = h_self.unsqueeze(1).expand(-1, h_neigh.size(1), -1)  # [num_nodes, num_max_edges, hidden_size]\n",
    "        # 将自身状态和邻边状态合并\n",
    "        combined_h = torch.cat([h_self_expanded, h_neigh], dim=-1)  # [num_nodes, num_max_edges, 2 * hidden_size]\n",
    "        \n",
    "        # 计算注意力分数\n",
    "        scores = self.fc(combined_h.view(-1, 2 * self.hidden_size)).view(h_self.size(0), h_neigh.size(1))  # [num_nodes, num_max_edges]\n",
    "        \n",
    "        # 添加自身对自身的注意力\n",
    "        self_attention = self.fc(torch.cat([h_self, h_self], dim=-1)).view(h_self.size(0), 1)  # [num_nodes, 1]\n",
    "        scores = torch.cat([self_attention, scores], dim=1)  # [num_nodes, num_max_edges + 1]\n",
    "        \n",
    "        return torch.softmax(scores, dim=1)  # [num_nodes, num_max_edges + 1]\n",
    "\n",
    "class EdgeAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(EdgeAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.tranform_node = nn.Linear(hidden_size, hidden_size)\n",
    "        self.tranform_edge = nn.Linear(hidden_size, hidden_size)\n",
    "        self.attention_fc = nn.Linear(2 * hidden_size, 2)  # 输出两个权重：w1 和 w2\n",
    "\n",
    "    def forward(self, node_state, edge_state):\n",
    "        # node_state: [num_edges, hidden_size]\n",
    "        # edge_state: [num_edges, hidden_size]\n",
    "        node_state = self.tranform_node(node_state)\n",
    "        edge_state = self.tranform_edge(edge_state)\n",
    "        # 将节点状态和边状态拼接\n",
    "        combined_state = torch.cat([node_state, edge_state], dim=-1)  # [num_edges, 2 * hidden_size]\n",
    "        \n",
    "        # 计算注意力权重\n",
    "        weights = self.attention_fc(combined_state)  # [num_edges, 2]\n",
    "        weights = torch.softmax(weights, dim=1)  # 归一化权重\n",
    "        \n",
    "        # 计算新的边状态\n",
    "        new_edge_state = weights[:, 0].unsqueeze(1) * node_state + weights[:, 1].unsqueeze(1) * edge_state  # [num_edges, hidden_size]\n",
    "        \n",
    "        return new_edge_state\n",
    "    \n",
    "class NodeAttention_multihead(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads=4):\n",
    "        super(NodeAttention_multihead, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # 为每个头创建独立的变换矩阵\n",
    "        self.transform_edge = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_heads)])  \n",
    "        self.transform_node = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_heads)])  \n",
    "        self.fc = nn.ModuleList([nn.Linear(2 * hidden_size, 1) for _ in range(num_heads)])  \n",
    "\n",
    "    def forward(self, h_self, h_neigh):\n",
    "        # h_self: [num_nodes, hidden_size]\n",
    "        # h_neigh: [num_nodes, num_max_edges, hidden_size]\n",
    "\n",
    "        head_outputs = []\n",
    "        for i in range(self.num_heads):\n",
    "            # 对节点和邻边应用独立变换\n",
    "            transformed_self = self.transform_node[i](h_self)  # [num_nodes, hidden_size]\n",
    "            transformed_neigh = self.transform_edge[i](h_neigh)  # [num_nodes, num_max_edges, hidden_size]\n",
    "\n",
    "            # 将自身状态复制到每个边的数量，然后和邻边状态合并\n",
    "            combined_h = torch.cat([\n",
    "                transformed_self.unsqueeze(1).expand(-1, h_neigh.size(1), -1),  # [num_nodes, num_max_edges, hidden_size]\n",
    "                transformed_neigh  # [num_nodes, num_max_edges, hidden_size]\n",
    "            ], dim=-1)  # [num_nodes, num_max_edges, 2 * hidden_size]\n",
    "\n",
    "            # 计算注意力分数\n",
    "            scores = self.fc[i](combined_h.view(-1, 2 * self.hidden_size)).view(h_self.size(0), h_neigh.size(1))  # [num_nodes, num_max_edges]\n",
    "            # 添加自身对自身的注意力\n",
    "            self_attention = self.fc[i](torch.cat([h_self, h_self], dim=-1)).view(h_self.size(0), 1)  # [num_nodes, 1]\n",
    "            scores = torch.cat([self_attention, scores], dim=1)  # [num_nodes, num_max_edges + 1]\n",
    "            head_outputs.append(scores)\n",
    "\n",
    "        # 将所有头的输出进行平均\n",
    "        scores = torch.stack(head_outputs, dim=2).mean(dim=2)  # [num_nodes, num_max_edges]\n",
    "        return torch.softmax(scores, dim=1)  # [num_nodes, num_max_edges]\n",
    "\n",
    "class EdgeAttention_multihead(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads=4):\n",
    "        super(EdgeAttention_multihead, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.transform_node = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_heads)])\n",
    "        self.transform_edge = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_heads)])\n",
    "        self.attention_fc = nn.ModuleList([nn.Linear(2 * hidden_size, 2) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, node_state, edge_state):\n",
    "        # node_state: [num_edges, hidden_size]\n",
    "        # edge_state: [num_edges, hidden_size]\n",
    "\n",
    "        head_outputs = []\n",
    "        for i in range(self.num_heads):\n",
    "            transformed_node = self.transform_node[i](node_state)  # [num_edges, hidden_size]\n",
    "            transformed_edge = self.transform_edge[i](edge_state)  # [num_edges, hidden_size]\n",
    "\n",
    "            # 将节点状态和边状态拼接\n",
    "            combined_state = torch.cat([transformed_node, transformed_edge], dim=-1)  # [num_edges, 2 * hidden_size]\n",
    "\n",
    "            # 计算注意力权重\n",
    "            weights = self.attention_fc[i](combined_state)  # [num_edges, 2]\n",
    "            weights = torch.softmax(weights, dim=1)  # [num_edges, 2]\n",
    "\n",
    "            # 根据权重计算新的边状态\n",
    "            new_edge_state = weights[:, 0].unsqueeze(1) * transformed_node + weights[:, 1].unsqueeze(1) * transformed_edge  # [num_edges, hidden_size]\n",
    "            head_outputs.append(new_edge_state)\n",
    "\n",
    "        # 将所有头的输出进行平均\n",
    "        new_edge_state = torch.stack(head_outputs, dim=2).mean(dim=2)  # [num_edges, hidden_size]\n",
    "        return new_edge_state\n",
    "\n",
    "\n",
    "# MPNEncodr类，负责计算图的编码过程，首先将每条边转换为一个隐藏状态，然后通过多次message_passing来更新这些隐藏状态\n",
    "# 用来模型信息在图中的传递\n",
    "'''\n",
    "要训练的权重参数如下：\n",
    "W_i: 用于初始边特征到隐藏状态的转换\n",
    "W_h: 在每次message passing迭代中用于更新隐藏状态的权重\n",
    "W_o: 将最终的节点表示和原始的节点表示拼接后，用于生成最终的原子隐藏状态\n",
    "'''\n",
    "# 消息传递的逻辑：边的特征是原始边特征与源点特征的拼接，每一次传递过程中，边的特征会传递给终点节点\n",
    "class MPNEncoder(nn.Module):\n",
    "    def __init__(self, args, node_fdim, edge_fdim):\n",
    "        super(MPNEncoder, self).__init__()\n",
    "        self.node_fdim = node_fdim\n",
    "        self.edge_fdim = edge_fdim  # 这里的edge_fdim是原始的edge_fdim + node_fdim\n",
    "        self.hidden_size = args.hidden_size\n",
    "        self.bias = args.bias\n",
    "        self.depth = args.depth\n",
    "        self.dropout = args.dropout\n",
    "        self.device = args.device\n",
    "        self.aggregation = args.aggregation\n",
    "        self.aggregation_norm = args.aggregation_norm\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "        self.act_func = nn.ReLU()\n",
    "        self.cached_zero_vector = nn.Parameter(torch.zeros(self.hidden_size), requires_grad=False)\n",
    "\n",
    "        self.node_attention = NodeAttention(self.hidden_size)\n",
    "        self.edge_attention = EdgeAttention(self.hidden_size)\n",
    "\n",
    "        # Input\n",
    "        input_dim = self.edge_fdim\n",
    "        self.W_i = nn.Linear(input_dim, self.hidden_size)\n",
    "        w_h_input_size = self.hidden_size\n",
    "        self.W_i_nodes = nn.Linear(self.node_fdim, self.hidden_size)\n",
    "\n",
    "        # Shared weight matrix across depths (default)\n",
    "        self.W_e = nn.Linear(2 * self.hidden_size, self.hidden_size)\n",
    "        self.W_h = nn.Linear(w_h_input_size, self.hidden_size)\n",
    "        self.W_o = nn.Linear(self.node_fdim + self.hidden_size, self.hidden_size)\n",
    "    \n",
    "    def forward(self, batch_graph, encoded_graph_infos):\n",
    "        f_nodes, f_edges, a2b, b2a, a_scope, b_scope = batch_graph.get_components()\n",
    "        f_nodes, f_edges, a2b, b2a, = f_nodes.to(self.device), f_edges.to(self.device), a2b.to(self.device), b2a.to(self.device)\n",
    "        self.W_i = self.W_i.to(self.device)\n",
    "        self.W_h = self.W_h.to(self.device)\n",
    "        self.W_o = self.W_o.to(self.device)\n",
    "\n",
    "        # Initial transformations\n",
    "        edge_message = self.act_func(self.W_i(f_edges))  # Transform edge features    num_edges * hidden_size\n",
    "        nodes_message = self.act_func(self.W_i_nodes(f_nodes))  # Transform node features   num_nodes * hidden_size\n",
    "\n",
    "        # Message passing\n",
    "        for depth in range(self.depth):\n",
    "            # Gather messages from edges to nodes\n",
    "            nei_a_message = index_select_ND(edge_message, a2b)  # [num_nodes, num_max_edges, hidden_size]\n",
    "            \n",
    "            # 计算注意力分数，包括节点自身状态\n",
    "            attention_scores = self.node_attention(nodes_message, nei_a_message)  # [num_nodes, num_max_edges + 1]\n",
    "            # 使用注意力分数加权邻边消息\n",
    "            weighted_messages = attention_scores[:, 1:].unsqueeze(-1) * nei_a_message  # [num_nodes, num_max_edges, hidden_size]\n",
    "            aggregated_message = weighted_messages.sum(dim=1)  # [num_nodes, hidden_size]\n",
    "            \n",
    "            # 加上自身消息的权重\n",
    "            self_message = attention_scores[:, 0].unsqueeze(1) * nodes_message  # [num_nodes, hidden_size]\n",
    "            nodes_message = self.act_func(self.W_h(self_message + aggregated_message))  # [num_nodes, hidden_size]\n",
    "\n",
    "            src_node_states = nodes_message[b2a]\n",
    "            edge_message = self.edge_attention(src_node_states, edge_message)\n",
    "\n",
    "\n",
    "        # Prepare output\n",
    "        final_node_representation = torch.cat([f_nodes, nodes_message], dim=1)\n",
    "        node_hiddens = self.act_func(self.W_o(final_node_representation))\n",
    "        node_hiddens = self.dropout_layer(node_hiddens)\n",
    "        \n",
    "        # readout\n",
    "        graph_vecs = []\n",
    "        for i, (a_start, a_size) in enumerate(a_scope):\n",
    "            if a_size == 0:\n",
    "                graph_vecs.append(self.cached_zero_vector)\n",
    "            else:\n",
    "                # print('graph_vecs_size: ', len(graph_vecs))\n",
    "                cur_hiddens = node_hiddens.narrow(0, a_start, a_size)\n",
    "                # print('cur_hiddens_size: ', cur_hiddens.size())\n",
    "                graph_vector = cur_hiddens\n",
    "                if self.aggregation == 'mean':\n",
    "                    graph_vector = graph_vector.sum(dim = 0) / a_size\n",
    "                elif self.aggregation == 'sum':\n",
    "                    graph_vector = graph_vector.sum(dim = 0)\n",
    "                elif self.aggregation == 'norm':\n",
    "                    graph_vector = graph_vector.sum(dim = 0) / self.aggregation_norm\n",
    "            graph_vecs.append(graph_vector)\n",
    "        graph_vecs = torch.stack(graph_vecs, dim = 0)\n",
    "        encoded_graph_infos_tensor = torch.tensor(encoded_graph_infos, dtype=torch.float).to(self.device)\n",
    "        graph_vecs = torch.cat([graph_vecs, encoded_graph_infos_tensor], dim=1)\n",
    "        return graph_vecs\n",
    "\n",
    "class MPN(nn.Module):\n",
    "    def __init__(self, args, node_fdim=None, edge_fdim=None):\n",
    "        super(MPN, self).__init__()\n",
    "        self.node_fdim = node_fdim or get_node_fdim()\n",
    "        self.edge_fdim = edge_fdim or get_edge_fdim()\n",
    "        self.device = args.device\n",
    "        self.encoder = MPNEncoder(args, self.node_fdim, self.edge_fdim)\n",
    "\n",
    "    def forward(self, batch_comp_graph, encoded_graph_infos):\n",
    "        if type(batch_comp_graph) != BatchCompGraph:\n",
    "            batch_comp_graph = BatchCompGraph(batch_comp_graph)\n",
    "        return self.encoder(batch_comp_graph, encoded_graph_infos)\n",
    "    \n",
    "class Comp_Model(nn.Module):\n",
    "    def __init__(self, args, graph_info_dim):\n",
    "        super(Comp_Model, self).__init__()\n",
    "        self.classification = args.dataset_type == 'classification'\n",
    "        self.output_size = args.num_tasks\n",
    "        if self.classification:\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "        self.create_encoder(args)\n",
    "        self.create_ffn(args, graph_info_dim)\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def create_encoder(self, args):\n",
    "        self.encoder = MPN(args)\n",
    "\n",
    "    def create_ffn(self, args, graph_info_dim):\n",
    "        first_linear_dim = args.hidden_size + graph_info_dim  # 加上 encoded_graph_info 的长度\n",
    "        dropout = nn.Dropout(args.dropout)\n",
    "        activation = nn.ReLU()\n",
    "        ffn = [dropout, nn.Linear(first_linear_dim, args.ffn_hidden_size)]\n",
    "        for _ in range(args.ffn_num_layers - 2):\n",
    "            ffn.extend([activation, dropout, nn.Linear(args.ffn_hidden_size, args.ffn_hidden_size)])\n",
    "        ffn.extend([activation, dropout, nn.Linear(args.ffn_hidden_size, self.output_size)])\n",
    "        self.ffn = nn.Sequential(*ffn)\n",
    "\n",
    "    def forward(self, batch, encoded_graph_infos):\n",
    "        output = self.ffn(self.encoder(batch, encoded_graph_infos))\n",
    "        if self.classification:\n",
    "            output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = Comp_Model(args, graph_info_dim())\n",
    "model = model.to(args.device)\n",
    "print(model)\n",
    "\n",
    "class NoamLR(_LRScheduler):\n",
    "    \"\"\"\n",
    "    Noam learning rate scheduler with piecewise linear increase and exponential decay.\n",
    "\n",
    "    The learning rate increases linearly from init_lr to max_lr over the course of\n",
    "    the first warmup_steps (where :code:`warmup_steps = warmup_epochs * steps_per_epoch`).\n",
    "    Then the learning rate decreases exponentially from :code:`max_lr` to :code:`final_lr` over the\n",
    "    course of the remaining :code:`total_steps - warmup_steps` (where :code:`total_steps =\n",
    "    total_epochs * steps_per_epoch`). This is roughly based on the learning rate\n",
    "    schedule from `Attention is All You Need <https://arxiv.org/abs/1706.03762>`_, section 5.3.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 optimizer: Optimizer,\n",
    "                 warmup_epochs: List[Union[float, int]],\n",
    "                 total_epochs: List[int],\n",
    "                 steps_per_epoch: int,\n",
    "                 init_lr: List[float],\n",
    "                 max_lr: List[float],\n",
    "                 final_lr: List[float]):\n",
    "\n",
    "        assert len(optimizer.param_groups) == len(warmup_epochs) == len(total_epochs) == len(init_lr) == \\\n",
    "               len(max_lr) == len(final_lr)\n",
    "\n",
    "        self.num_lrs = len(optimizer.param_groups)\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = np.array(warmup_epochs)\n",
    "        self.total_epochs = np.array(total_epochs)\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.init_lr = np.array(init_lr)\n",
    "        self.max_lr = np.array(max_lr)\n",
    "        self.final_lr = np.array(final_lr)\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.lr = init_lr\n",
    "        self.warmup_steps = (self.warmup_epochs * self.steps_per_epoch).astype(int)\n",
    "        self.total_steps = self.total_epochs * self.steps_per_epoch\n",
    "        self.linear_increment = (self.max_lr - self.init_lr) / self.warmup_steps\n",
    "\n",
    "        self.exponential_gamma = (self.final_lr / self.max_lr) ** (1 / (self.total_steps - self.warmup_steps))\n",
    "\n",
    "        super(NoamLR, self).__init__(optimizer)\n",
    "\n",
    "    def get_lr(self) -> List[float]:\n",
    "        return list(self.lr)\n",
    "\n",
    "    def step(self, current_step: int = None):\n",
    "        if current_step is not None:\n",
    "            self.current_step = current_step\n",
    "        else:\n",
    "            self.current_step += 1\n",
    "\n",
    "        for i in range(self.num_lrs):\n",
    "            if self.current_step <= self.warmup_steps[i]:\n",
    "                self.lr[i] = self.init_lr[i] + self.current_step * self.linear_increment[i]\n",
    "            elif self.current_step <= self.total_steps[i]:\n",
    "                self.lr[i] = self.max_lr[i] * (self.exponential_gamma[i] ** (self.current_step - self.warmup_steps[i]))\n",
    "            else:  # theoretically this case should never be reached since training should stop at total_steps\n",
    "                self.lr[i] = self.final_lr[i]\n",
    "\n",
    "            self.optimizer.param_groups[i]['lr'] = self.lr[i]\n",
    "\n",
    "def construct_compgraph_batch(data):\n",
    "    data = CompGraphDataset(data)\n",
    "    # return data.batch_graph()  # Forces computation and caching of the BatchCompGraph for the CompGraphs\n",
    "    return data\n",
    "\n",
    "class CompGraphSampler(Sampler):\n",
    "    def __init__(self, dataset, shuffle=False, seed=0):\n",
    "        super(Sampler, self).__init__()\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.shuffle = shuffle\n",
    "        self._random = Random(seed)\n",
    "        self.positive_indices = self.negative_indices = None\n",
    "        self.length = len(self.dataset)\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = list(range(len(self.dataset)))\n",
    "        if self.shuffle:\n",
    "            self._random.shuffle(indices)\n",
    "        return iter(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "class CompGraphDataLoader(DataLoader):\n",
    "    def __init__(self,\n",
    "                 dataset: CompGraphDataset,\n",
    "                 batch_size: int = 32,\n",
    "                 num_workers: int = 8,\n",
    "                 shuffle: bool = False,\n",
    "                 seed: int = 0):\n",
    "\n",
    "        self._dataset = dataset\n",
    "        self._batch_size = batch_size\n",
    "        self._num_workers = num_workers\n",
    "        self._shuffle = shuffle\n",
    "        self._seed = seed\n",
    "        self._context = None\n",
    "        self._class_balance = False\n",
    "        self._timeout = 0\n",
    "        is_main_thread = threading.current_thread() is threading.main_thread()\n",
    "        \n",
    "        if not is_main_thread and self._num_workers > 0:\n",
    "            self._context = 'forkserver'  # In order to prevent a hanging\n",
    "            self._timeout = 3600  # Just for sure that the DataLoader won't hang\n",
    "\n",
    "        self._sampler = CompGraphSampler(\n",
    "            dataset=self._dataset,\n",
    "            shuffle=self._shuffle,\n",
    "            seed=self._seed\n",
    "        )\n",
    "\n",
    "        super(CompGraphDataLoader, self).__init__(\n",
    "            dataset=self._dataset,\n",
    "            batch_size=self._batch_size,\n",
    "            sampler=self._sampler,\n",
    "            num_workers=self._num_workers,\n",
    "            collate_fn=construct_compgraph_batch,\n",
    "            multiprocessing_context=self._context,\n",
    "            timeout=self._timeout\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def targets(self) -> List[List[Optional[float]]]:\n",
    "        if self._class_balance or self._shuffle:\n",
    "            raise ValueError('Cannot safely extract targets when class balance or shuffle are enabled.')\n",
    "\n",
    "        return [self._dataset[index].targets for index in self._sampler]\n",
    "\n",
    "    @property\n",
    "    def iter_size(self) -> int:\n",
    "        return len(self._sampler)\n",
    "\n",
    "    def __iter__(self) -> Iterator[CompGraphDataset]:\n",
    "        return super(CompGraphDataLoader, self).__iter__()\n",
    "    \n",
    "\n",
    "data = CompGraphDataset([\n",
    "    CompGraphDatapoint(\n",
    "        node_info=node_info_set[i],\n",
    "        edge_info=edge_info_set[i],\n",
    "        graph_info=graph_info_set[i],\n",
    "        result=result_set[i],\n",
    "        op_vocab=op_vocab\n",
    "    ) for i in range(len(node_info_set))\n",
    "])\n",
    "\n",
    "random = Random()\n",
    "sizes = [0.8, 0.1, 0.1]\n",
    "\n",
    "indices = list(range(len(data)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_size = int(sizes[0] * len(data))\n",
    "train_val_size = int((sizes[0] + sizes[1]) * len(data))\n",
    "\n",
    "train_source = [data[i] for i in indices[:train_size]]\n",
    "val = [data[i] for i in indices[train_size:train_val_size]]\n",
    "test = [data[i] for i in indices[train_val_size:]]\n",
    "\n",
    "train_data = CompGraphDataset(train_source)\n",
    "val_data = CompGraphDataset(val)\n",
    "test_data = CompGraphDataset(test)\n",
    "\n",
    "train_data_loader = CompGraphDataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = args.batch_size,\n",
    "    num_workers= 8,\n",
    "    shuffle = True,\n",
    "    seed = args.seed\n",
    ")\n",
    "\n",
    "val_data_loader = CompGraphDataLoader(\n",
    "    dataset = val_data,\n",
    "    batch_size = args.batch_size,\n",
    "    num_workers= 8\n",
    ")\n",
    "\n",
    "test_data_loader = CompGraphDataLoader(\n",
    "    dataset = test_data,\n",
    "    batch_size = args.batch_size,\n",
    "    num_workers= 8,\n",
    ")\n",
    "\n",
    "# optimizer\n",
    "params = [{'params': model.parameters(), 'lr': args.init_lr, 'weight_decay': 0}]\n",
    "optimizer = Adam(params)\n",
    "metric_func = mean_squared_error\n",
    "\n",
    "# scheduler\n",
    "scheduler = NoamLR(\n",
    "    optimizer=optimizer,\n",
    "    warmup_epochs=[args.warmup_epochs],\n",
    "    total_epochs=[args.epochs] * args.num_lrs,\n",
    "    steps_per_epoch=len(train_data) // args.batch_size,\n",
    "    init_lr=[args.init_lr],\n",
    "    max_lr=[args.max_lr],\n",
    "    final_lr=[args.final_lr]\n",
    ")\n",
    "\n",
    "def train(model, train_data_loader, optimizer, scheduler, args):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_data_loader:\n",
    "        batch_graphs = batch.batch_graph()\n",
    "        encoded_graph_infos = [datapoint.graph_info for datapoint in batch]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_graphs, encoded_graph_infos)\n",
    "        targets = torch.tensor(batch.results(), dtype=torch.float).to(args.device)\n",
    "        loss = F.binary_cross_entropy(output.squeeze(1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_data_loader)\n",
    "\n",
    "def evaluate(model, data_loader, args, threshold=0.3):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    correct_predictions_positives = 0\n",
    "    total_samples = 0\n",
    "    total_positives = 0\n",
    "    predicted_positives = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch_graphs = batch.batch_graph()\n",
    "            encoded_graph_infos = [datapoint.graph_info for datapoint in batch]\n",
    "            output = model(batch_graphs, encoded_graph_infos)\n",
    "            targets = torch.tensor(batch.results(), dtype=torch.float).to(args.device)\n",
    "            loss = F.binary_cross_entropy(output.squeeze(1), targets)\n",
    "            total_loss += loss.item()\n",
    "            predictions = (output.squeeze(1) >= threshold).long()\n",
    "            correct_predictions += (predictions == targets).sum().item()\n",
    "            correct_predictions_positives += ((predictions == 1) & (targets == 1)).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "            total_positives += (targets == 1).sum().item()\n",
    "            predicted_positives += (predictions == 1).sum().item()\n",
    "    overall_accuracy = correct_predictions / total_samples * 100 if total_samples > 0 else 0\n",
    "    positive_accuracy = correct_predictions_positives / total_positives * 100 if total_positives > 0 else 0\n",
    "    return total_loss / len(data_loader), overall_accuracy, positive_accuracy, total_positives, predicted_positives\n",
    "\n",
    "def main(args):\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_accuracy = 0\n",
    "    best_model_state = model.state_dict()\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        train_loss = train(model, train_data_loader, optimizer, scheduler, args)\n",
    "        val_loss, val_accuracy, val_positive_accuracy, total_positives, predicted_positives = evaluate(model, val_data_loader, args)\n",
    "        print(f'Epoch {epoch+1}/{args.epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, '\n",
    "              f'Positive Accuracy: {val_positive_accuracy:.2f}%, Total Positives: {total_positives}, Predicted Positives: {predicted_positives}')\n",
    "\n",
    "        # Check if the current model is better than the best model so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            # Save the best model state\n",
    "            torch.save(best_model_state, 'ablation_best_model.pth')\n",
    "\n",
    "    # Load the best model state\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_loss, test_accuracy, test_positive_accuracy, test_total_positives, test_predicted_positives = evaluate(model, test_data_loader, args)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%, '\n",
    "          f'Test Positive Accuracy: {test_positive_accuracy:.2f}%, Test Total Positives: {test_total_positives}, Test Predicted Positives: {test_predicted_positives}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_info': [[4, 'Input', 0],\n",
       "  [5, 'core.Clip', 1],\n",
       "  [2, 'Concat ', 3],\n",
       "  [1, 'Cast ', 1],\n",
       "  [3, 'core.ReduceMax', 1]],\n",
       " 'edge_info': [[4, 5, [19, 14, 10, 1, 0], 'i64', 0],\n",
       "  [5, 2, [19, 14, 10, 1, 0], 'i64', 1],\n",
       "  [5, 2, [19, 14, 10, 1, 0], 'i64', 2],\n",
       "  [5, 2, [19, 14, 10, 1, 0], 'i64', 3],\n",
       "  [5, 1, [19, 14, 10, 1, 0], 'i64', 4],\n",
       "  [1, 3, [19, 14, 10, 1, 0], 'f64', 5]],\n",
       " 'graph_info': [5,\n",
       "  6,\n",
       "  ['Input', 'Cast ', 'core.ReduceMax', 'Concat ', 'core.Clip']],\n",
       " 'result': 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dataset_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.6719, Val Loss: 0.5391, Val Accuracy: 54.75%, Positive Accuracy: 95.54%, Total Positives: 920, Predicted Positives: 2156\n",
      "Epoch 2/100, Train Loss: 0.4731, Val Loss: 0.3711, Val Accuracy: 83.21%, Positive Accuracy: 82.93%, Total Positives: 920, Predicted Positives: 1095\n",
      "Epoch 3/100, Train Loss: 0.4083, Val Loss: 0.3507, Val Accuracy: 86.23%, Positive Accuracy: 76.74%, Total Positives: 920, Predicted Positives: 893\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 884\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    883\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model, train_data_loader, optimizer, scheduler, args)\n\u001b[0;32m--> 884\u001b[0m     val_loss, val_accuracy, val_positive_accuracy, total_positives, predicted_positives \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    886\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositive Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_positive_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Total Positives: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_positives\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Predicted Positives: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_positives\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;66;03m# Check if the current model is better than the best model so far\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 863\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader, args, threshold)\u001b[0m\n\u001b[1;32m    861\u001b[0m batch_graphs \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mbatch_graph()\n\u001b[1;32m    862\u001b[0m encoded_graph_infos \u001b[38;5;241m=\u001b[39m [datapoint\u001b[38;5;241m.\u001b[39mgraph_info \u001b[38;5;28;01mfor\u001b[39;00m datapoint \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m--> 863\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_graphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_graph_infos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch\u001b[38;5;241m.\u001b[39mresults(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    865\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m), targets)\n",
      "File \u001b[0;32m~/anaconda3/envs/apache-tvm-v0.10.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/apache-tvm-v0.10.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 623\u001b[0m, in \u001b[0;36mComp_Model.forward\u001b[0;34m(self, batch, encoded_graph_infos)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, encoded_graph_infos):\n\u001b[0;32m--> 623\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_graph_infos\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification:\n\u001b[1;32m    625\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/apache-tvm-v0.10.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/apache-tvm-v0.10.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 596\u001b[0m, in \u001b[0;36mMPN.forward\u001b[0;34m(self, batch_comp_graph, encoded_graph_infos)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(batch_comp_graph) \u001b[38;5;241m!=\u001b[39m BatchCompGraph:\n\u001b[1;32m    595\u001b[0m     batch_comp_graph \u001b[38;5;241m=\u001b[39m BatchCompGraph(batch_comp_graph)\n\u001b[0;32m--> 596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_comp_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_graph_infos\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/apache-tvm-v0.10.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/apache-tvm-v0.10.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 542\u001b[0m, in \u001b[0;36mMPNEncoder.forward\u001b[0;34m(self, batch_graph, encoded_graph_infos)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# Message passing\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m depth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# Gather messages from edges to nodes\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m     nei_a_message \u001b[38;5;241m=\u001b[39m \u001b[43mindex_select_ND\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma2b\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [num_nodes, num_max_edges, hidden_size]\u001b[39;00m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;66;03m# 计算注意力分数，包括节点自身状态\u001b[39;00m\n\u001b[1;32m    545\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_attention(nodes_message, nei_a_message)  \u001b[38;5;66;03m# [num_nodes, num_max_edges + 1]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 114\u001b[0m, in \u001b[0;36mindex_select_ND\u001b[0;34m(source, index)\u001b[0m\n\u001b[1;32m    112\u001b[0m suffix_dim \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# (hidden_size,) 也就是source中除了第一个维度之外的所有维度的大小\u001b[39;00m\n\u001b[1;32m    113\u001b[0m final_size \u001b[38;5;241m=\u001b[39m index_size \u001b[38;5;241m+\u001b[39m suffix_dim  \u001b[38;5;66;03m# (num_nodes/num_edges, max_num_edges, hidden_size)\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (num_nodes/num_edges * max_num_edges, hidden_size)\u001b[39;00m\n\u001b[1;32m    115\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mview(final_size)  \u001b[38;5;66;03m# (num_nodes/num_edges, max_num_edges, hidden_size)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader, args):\n",
    "    \"\"\"\n",
    "    预测测试用例触发 bug 的概率，并按照概率值降序排序。\n",
    "\n",
    "    参数:\n",
    "        model: 已经训练好的模型。\n",
    "        data_loader: DataLoader 实例，用于加载测试数据集。\n",
    "        args: 参数配置。\n",
    "\n",
    "    返回:\n",
    "        bug_indices: 按照触发 bug 概率降序排序的测试用例索引序列。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch_graphs = batch.batch_graph()\n",
    "            encoded_graph_infos = [datapoint.graph_info for datapoint in batch]\n",
    "            output = model(batch_graphs, encoded_graph_infos)\n",
    "            predictions.extend(output.squeeze(1).tolist())\n",
    "\n",
    "    # 将预测结果和对应的测试用例组合成元组列表\n",
    "    bug_probabilities = list(enumerate(predictions))\n",
    "\n",
    "    # 按照触发 bug 概率降序排序\n",
    "    bug_probabilities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 提取排序后的测试用例索引\n",
    "    bug_indices = [idx for idx, _ in bug_probabilities]\n",
    "\n",
    "    return bug_indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "json_filename = 'demo_test_data_info.json'\n",
    "with open(json_filename, 'r') as jsonfile:\n",
    "    demo_test_data_info = json.load(jsonfile)\n",
    "json_filename = 'demo_test_time_info.json'\n",
    "with open(json_filename, 'r') as jsonfile:\n",
    "    demo_test_time_info = json.load(jsonfile)\n",
    "test_node_info_set = [item['node_info'] for item in demo_test_data_info]\n",
    "test_edge_info_set = [item['edge_info'] for item in demo_test_data_info]\n",
    "test_graph_info_set = [item['graph_info'] for item in demo_test_data_info]\n",
    "test_result_set = [item['result'] for item in demo_test_data_info]\n",
    "\n",
    "demo_test_data = CompGraphDataset([\n",
    "    CompGraphDatapoint(\n",
    "        node_info = test_node_info_set[i],\n",
    "        edge_info = test_edge_info_set[i],\n",
    "        graph_info = test_graph_info_set[i],\n",
    "        result = test_result_set[i],\n",
    "        op_vocab=op_vocab\n",
    "    ) for i in range(len(test_node_info_set))\n",
    "])\n",
    "demo_test_data_loader = CompGraphDataLoader(\n",
    "    dataset = demo_test_data,\n",
    "    batch_size = args.batch_size,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    "    seed = args.seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1627, Test Accuracy: 88.50%, Test Positive Accuracy: 80.00%, Test Total Positives: 10, Test Predicted Positives: 29\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy, test_positive_accuracy, test_total_positives, test_predicted_positives = evaluate(model, demo_test_data_loader, args)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%, '\n",
    "          f'Test Positive Accuracy: {test_positive_accuracy:.2f}%, Test Total Positives: {test_total_positives}, Test Predicted Positives: {test_predicted_positives}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46,\n",
       " 30,\n",
       " 67,\n",
       " 171,\n",
       " 194,\n",
       " 80,\n",
       " 64,\n",
       " 38,\n",
       " 138,\n",
       " 104,\n",
       " 121,\n",
       " 29,\n",
       " 50,\n",
       " 102,\n",
       " 9,\n",
       " 99,\n",
       " 3,\n",
       " 178,\n",
       " 174,\n",
       " 48,\n",
       " 163,\n",
       " 134,\n",
       " 189,\n",
       " 2,\n",
       " 122,\n",
       " 24,\n",
       " 172,\n",
       " 129,\n",
       " 83,\n",
       " 192,\n",
       " 88,\n",
       " 141,\n",
       " 151,\n",
       " 187,\n",
       " 51,\n",
       " 12,\n",
       " 146,\n",
       " 23,\n",
       " 5,\n",
       " 25,\n",
       " 110,\n",
       " 32,\n",
       " 109,\n",
       " 116,\n",
       " 136,\n",
       " 93,\n",
       " 42,\n",
       " 108,\n",
       " 143,\n",
       " 191,\n",
       " 95,\n",
       " 77,\n",
       " 16,\n",
       " 87,\n",
       " 183,\n",
       " 195,\n",
       " 137,\n",
       " 97,\n",
       " 79,\n",
       " 158,\n",
       " 177,\n",
       " 6,\n",
       " 11,\n",
       " 35,\n",
       " 150,\n",
       " 186,\n",
       " 0,\n",
       " 147,\n",
       " 170,\n",
       " 81,\n",
       " 53,\n",
       " 113,\n",
       " 114,\n",
       " 65,\n",
       " 166,\n",
       " 188,\n",
       " 176,\n",
       " 45,\n",
       " 173,\n",
       " 18,\n",
       " 167,\n",
       " 58,\n",
       " 63,\n",
       " 84,\n",
       " 103,\n",
       " 26,\n",
       " 165,\n",
       " 181,\n",
       " 69,\n",
       " 43,\n",
       " 27,\n",
       " 17,\n",
       " 127,\n",
       " 115,\n",
       " 82,\n",
       " 131,\n",
       " 61,\n",
       " 10,\n",
       " 168,\n",
       " 41,\n",
       " 120,\n",
       " 179,\n",
       " 49,\n",
       " 21,\n",
       " 28,\n",
       " 190,\n",
       " 54,\n",
       " 197,\n",
       " 36,\n",
       " 56,\n",
       " 164,\n",
       " 148,\n",
       " 33,\n",
       " 22,\n",
       " 72,\n",
       " 92,\n",
       " 74,\n",
       " 162,\n",
       " 94,\n",
       " 86,\n",
       " 85,\n",
       " 135,\n",
       " 198,\n",
       " 139,\n",
       " 70,\n",
       " 75,\n",
       " 111,\n",
       " 98,\n",
       " 66,\n",
       " 132,\n",
       " 90,\n",
       " 91,\n",
       " 169,\n",
       " 184,\n",
       " 13,\n",
       " 71,\n",
       " 57,\n",
       " 185,\n",
       " 123,\n",
       " 130,\n",
       " 153,\n",
       " 19,\n",
       " 20,\n",
       " 68,\n",
       " 152,\n",
       " 157,\n",
       " 161,\n",
       " 156,\n",
       " 124,\n",
       " 59,\n",
       " 101,\n",
       " 78,\n",
       " 1,\n",
       " 7,\n",
       " 133,\n",
       " 199,\n",
       " 34,\n",
       " 128,\n",
       " 155,\n",
       " 62,\n",
       " 60,\n",
       " 140,\n",
       " 112,\n",
       " 8,\n",
       " 96,\n",
       " 107,\n",
       " 37,\n",
       " 73,\n",
       " 118,\n",
       " 52,\n",
       " 119,\n",
       " 154,\n",
       " 14,\n",
       " 180,\n",
       " 159,\n",
       " 89,\n",
       " 106,\n",
       " 117,\n",
       " 15,\n",
       " 125,\n",
       " 100,\n",
       " 4,\n",
       " 144,\n",
       " 55,\n",
       " 126,\n",
       " 31,\n",
       " 76,\n",
       " 105,\n",
       " 149,\n",
       " 40,\n",
       " 145,\n",
       " 175,\n",
       " 193,\n",
       " 39,\n",
       " 142,\n",
       " 182,\n",
       " 160,\n",
       " 196,\n",
       " 44,\n",
       " 47]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_indices = predict(model, demo_test_data_loader, args)\n",
    "bug_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 30, 46, 67, 80, 108, 138, 163, 171, 187]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_bug_indices = []\n",
    "for i in range(len(test_result_set)):\n",
    "    if test_result_set[i]!=0:\n",
    "        real_bug_indices.append(i)\n",
    "real_bug_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
